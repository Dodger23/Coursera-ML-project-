}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nv = nearZeroVar(training)
nv
c = training
d = vector()
for(i in 1:(ncol(c) - 1) )
{
if(class(c[,i]) != "numeric" )
{
d = c(d , i)
#print(c(names(c)[i]))
}
}
c = c[,-d]
#names(c)
#str(c)
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nv = nearZeroVar(training , saveMetrics = T)
nv
c = training
d = vector()
for(i in 1:(ncol(c) - 1) )
{
if(class(c[,i]) != "numeric" )
{
d = c(d , i)
#print(c(names(c)[i]))
}
}
c = c[,-d]
#names(c)
#str(c)
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
dim(training)
c = training
d = vector()
for(i in 1:(ncol(c) - 1) )
{
if(class(c[,i]) != "numeric" )
{
d = c(d , i)
#print(c(names(c)[i]))
}
}
c = c[,-d]
#names(c)
#str(c)
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
c = training
d = vector()
for(i in 1:(ncol(c) - 1) )
{
if(class(c[,i]) != "numeric" )
{
d = c(d , i)
#print(c(names(c)[i]))
}
}
c = c[,-d]
#names(c)
#str(c)
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
modCtl <- trainControl(method = 'cv', number = 5)
#set.seed(2384)
#modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
#modRf$finalModel
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
modCtl <- trainControl(method = 'cv', number = 5)
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
modRf$finalModel
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
#p = predict(modelFit , test)
#confusionMatrix(p , test$classe)
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
m#odCtl <- trainControl(method = 'cv', number = 5)
#set.seed(2384)
#modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
#modRf$finalModel
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
p = predict(modRf , test)
confusionMatrix(p , test$classe)$tabel
confusionMatrix(p , test$classe)$overall[1]
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
#odCtl <- trainControl(method = 'cv', number = 5)
#set.seed(2384)
#modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
#modRf$finalModel
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
p = predict(modRf , test)
confusionMatrix(p , test$classe)$tabel
confusionMatrix(p , test$classe)$overall[1]
library(caret)
#data = read.csv("data/pml-training.csv")
explor = function(data)
{
head(data)
str(data)
summary(data)
names(data)
summary(data$classe)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
clean_data = function(data)
{
d = vector()
for(i in 1:ncol(data))
{
if(sum(is.na(data[,i])) > 0 )
{
#print(sum(is.na(data[,i])))
d = c(d , names(data)[i] )
}
}
d = c("X" , "user_name" , "cvtd_timestamp", d)
data = data[,-which(names(data) %in% d ) ]
data
}
#data = clean_data(data)
#inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
#training = data[inTrain , ]
#test = data[-inTrain , ]
#str(training)
nzv = nearZeroVar(training , saveMetrics = T)
keepFeat <- row.names(nzv[nzv$nzv == FALSE, ])
training <- training[, keepFeat]
training <- training[, colSums(is.na(training)) == 0]
dim(training)
#odCtl <- trainControl(method = 'cv', number = 5)
#set.seed(2384)
#modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
#modRf$finalModel
#modelFit = train(classe ~  ., method = "nb"  ,  data = trainPc  )
#modelFit
p = predict(modRf , test)
confusionMatrix(p , test$classe)
confusionMatrix(p , test$classe)$overall[1]
library(caret)
# Reading the data
data = read.csv("data/pml-training.csv")
# Splitting the data into 75% raining and 25% testing
inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
training = data[inTrain , ]
testing = data[-inTrain , ]
# Exploring the training data
explor = function(data)
{
str(data)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
explore(training)
#Because the data contains a lot of variables we need to remove similar ones to reduce computation complexity.
#Also the data contains a lot of NA's, so we need to clean it.
#If there were few NA's maybe we could use KNN, but with this number of NA's in the columns it's better to remove it .
## Cleaning the training data
clean_data = function(data)
{
nzv = nearZeroVar(data , saveMetrics = T)
keepFeat = row.names(nzv[nzv$nzv == FALSE, ])
data = data[, keepFeat]
data = data[, colSums(is.na(data)) == 0]
data
}
training = clean_data(training)
# Modeling
#Using cross validation and random forest
#Saving trainControl() call with required parameters
odCtl <- trainControl(method = 'cv', number = 5)
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
modRf$finalModel
# Predicting
pred = predict(modRf , testing)
confusionMatrix(pred , testing$classe)
confusionMatrix(pred , testing$classe)$overall[1]
# Qruiz
Quiz = read.csv("data/pml-testing.csv")
Qpred = predict(modRf , Quiz)
Qpred
library(caret)
# Reading the data
data = read.csv("data/pml-training.csv")
# Splitting the data into 75% raining and 25% testing
inTrain = createDataPartition(y= data$classe , p = 0.75 , list = FALSE)
training = data[inTrain , ]
testing = data[-inTrain , ]
# Exploring the training data
explore = function(data)
{
str(data)
find_na = apply(is.na(data),2,sum)
print(find_na)
}
explore(training)
#Because the data contains a lot of variables we need to remove similar ones to reduce computation complexity.
#Also the data contains a lot of NA's, so we need to clean it.
#If there were few NA's maybe we could use KNN, but with this number of NA's in the columns it's better to remove it .
## Cleaning the training data
clean_data = function(data)
{
nzv = nearZeroVar(data , saveMetrics = T)
keepFeat = row.names(nzv[nzv$nzv == FALSE, ])
data = data[, keepFeat]
data = data[, colSums(is.na(data)) == 0]
data
}
training = clean_data(training)
# Modeling
#Using cross validation and random forest
#Saving trainControl() call with required parameters
odCtl <- trainControl(method = 'cv', number = 5)
set.seed(2384)
modRf <- train(classe ~. , data = training, method = 'rf', trControl = modCtl)
modRf$finalModel
# Predicting
pred = predict(modRf , testing)
confusionMatrix(pred , testing$classe)
confusionMatrix(pred , testing$classe)$overall[1]
# Qruiz
Quiz = read.csv("data/pml-testing.csv")
Qpred = predict(modRf , Quiz)
Qpred
